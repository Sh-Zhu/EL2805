{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PyTorch Tutorial (Solved)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copyright [2020] [KTH Royal Institute of Technology] Licensed under the\n",
    "# Educational Community License, Version 2.0 (the \"License\"); you may\n",
    "# not use this file except in compliance with the License. You may\n",
    "# obtain a copy of the License at http://www.osedu.org/licenses/ECL-2.0\n",
    "# Unless required by applicable law or agreed to in writing,\n",
    "# software distributed under the License is distributed on an \"AS IS\"\n",
    "# BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express\n",
    "# or implied. See the License for the specific language governing\n",
    "# permissions and limitations under the License.\n",
    "#\n",
    "# Course: EL2805 - Reinforcement Learning - PyTorch Tutorial\n",
    "# Code author: [Alessio Russo - alessior@kth.se]\n",
    "# Last update: 25th October 2020, by alessior@kth.se\n",
    "\n",
    "# Start by importing the basic libraries\n",
    "import numpy as np               # Numerical computing\n",
    "import matplotlib.pyplot as plt  # Plotting utilities\n",
    "import torch                     # Basic Pytorch import\n",
    "import torch.nn as nn            # Imports neural networks blocks\n",
    "from ipywidgets import interact, IntSlider, FloatSlider"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Input/Target output data\n",
    "\n",
    "![alt text](data.png \"Data\")\n",
    "\n",
    "Define tensors for both the input data and the target output data.\n",
    "\n",
    "To create a tensor use the notation ```torch.tensor(data, dtype=torch.float64)``` (https://pytorch.org/docs/stable/generated/torch.tensor.html)\n",
    "\n",
    "\n",
    "- Make sure to use ```dtype=torch.float64```. This forces Pytorch to use double precision\n",
    "- ```requires_grad=False``` tells Pytorch to consider this variable as a parameter. Therefore it is not possible to compute the gradient with respect to this variable.\n",
    "- The data passed to ```torch.tensor()``` can be a list or numpy array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input (temp, rainfall, humidity)\n",
    "inputs = torch.tensor([[73, 67, 43], \n",
    "                       [91, 88, 64], \n",
    "                       [87, 134, 58], \n",
    "                       [102, 43, 37], \n",
    "                       [69, 96, 70]], dtype=torch.float32, requires_grad=False)\n",
    "\n",
    "# Target outputs (apples, oranges)\n",
    "target_outputs = torch.tensor([[56, 70],\n",
    "                               [81, 101],\n",
    "                               [119, 133],\n",
    "                               [22, 37],\n",
    "                               [103, 119]], dtype=torch.float32, requires_grad=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Create the neural network\n",
    "![alt text](nn.png \"Data\")\n",
    "\n",
    "Define a Neural network with 2 layers (input and output). The number of neurons should be a parameter of the class.  Notice that we expect a positive output from the network (hint: *is the target output positive or negative*?), therefore we should use an activation function that gives a positive output. We will use ReLU for the output neurons, and sigmoidal activations for the input layer to practice.\n",
    "\n",
    "Remember that\n",
    "- ReLU activation : $\\sigma(x) = \\max(0,x)$\n",
    "- Sigmoidal activation: $\\sigma(x) = \\frac{1}{1+e^{-x}}$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNet(nn.Module):\n",
    "    # In the init define each layer individually\n",
    "    # \\par `neurons` is used to define the number of input neurons\n",
    "    def __init__(self, neurons=6):\n",
    "        super().__init__()  # This line needs to called to properly setup the network\n",
    "        self.linear1 = nn.Linear(3, neurons) # Layer with 3 inputs and `neurons` output\n",
    "        self.act1 = nn.ReLU() # Activation function\n",
    "        self.linear2 = nn.Linear(neurons, 2) # Layer with `neurons` inputs and 2 outputs\n",
    "        self.act2 = nn.ReLU() # Activation function\n",
    "    \n",
    "    # In the forward function you define how each layer is\n",
    "    # interconnected. Observe that 'x' is the input.\n",
    "    def forward(self, x):\n",
    "        # First layer (input layer)\n",
    "        x = self.linear1(x)  \n",
    "        x = self.act1(x)\n",
    "        # Second layer (output)\n",
    "        x = self.linear2(x)\n",
    "        return x\n",
    "    \n",
    "# Pay attention, there is no need to define \"backward\" for the backward\n",
    "# pass. It is done by the library"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a utility function to train the model\n",
    "def fit(neurons, learning_rate, momentum, nesterov, plot=True):\n",
    "    # Initialize network and optimizer\n",
    "    model = NeuralNet(neurons)\n",
    "    # Define SGD optimizer with the parameters of the network and the\n",
    "    # given parameters (learning rate, momentum and nesterov)\n",
    "    opt = torch.optim.SGD(model.parameters(), learning_rate, momentum=momentum, nesterov=nesterov)\n",
    "    losses = []\n",
    "    # Train for 1000 epochs\n",
    "    for epoch in range(1000):\n",
    "        # Reset gradients\n",
    "        opt.zero_grad()\n",
    "        # Generate predictions\n",
    "        pred = model(inputs)\n",
    "        # Compute MSE loss\n",
    "        loss = nn.functional.mse_loss(pred, target_outputs)\n",
    "        # Append loss to loss vector (used for plotting)\n",
    "        losses.append(loss.item())\n",
    "        # Compute gradients\n",
    "        loss.backward()\n",
    "        # Compute backward step\n",
    "        opt.step()\n",
    "    if plot:\n",
    "        plt.plot(losses)\n",
    "        plt.grid(alpha=0.5)\n",
    "        plt.yscale('log')\n",
    "        plt.xlabel('Epoch')\n",
    "        plt.ylabel('Loss value')\n",
    "        plt.show()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fd797a896e894888b2f33c5053bb440f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=6, description='neurons', max=20, min=1), FloatSlider(value=1e-06, descrâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# This is a widget used to play with the parameters, works only in jupyter\n",
    "# if you have enabled the widgets! (should work if you follow the lab setup instructions)\n",
    "interact(fit, \n",
    "         neurons=IntSlider(value=6, min=1, max=20, step=1),\n",
    "         learning_rate=FloatSlider(value=1e-6, min=1e-7, max=1e-3, step=1e-6, readout_format='.7f'),\n",
    "         momentum=FloatSlider(value=0.9, min=0., max=1., step=1e-3, readout_format='.3f'),\n",
    "         nesterov=True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction: [[ 57.337082  70.18399 ]\n",
      " [ 82.35712  100.19418 ]\n",
      " [118.49289  133.90166 ]\n",
      " [ 22.055851  36.348156]\n",
      " [101.52115  118.758575]]\n",
      "Real values: tensor([[ 56.,  70.],\n",
      "        [ 81., 101.],\n",
      "        [119., 133.],\n",
      "        [ 22.,  37.],\n",
      "        [103., 119.]])\n"
     ]
    }
   ],
   "source": [
    "# Try model with 6 neurons, learning rate of 10^-6, momentum of 0.9 and no Nesterov\n",
    "model = fit(6, 1e-6, 0.9, False, plot=False);\n",
    "pred = model(inputs)\n",
    "print('Prediction: {}'.format(pred.detach().numpy()))\n",
    "print('Real values: {}'.format(target_outputs))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
